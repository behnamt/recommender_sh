{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "2.7.17-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2,
  "kernelspec": {
   "name": "collaborative",
   "display_name": "collaborative"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as ps\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import turicreate as tc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing CSV data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_raw = ps.read_csv('transactions.csv', names = ['SKU', 'CUSTOMER'], header = 1)\n",
    "products_raw = ps.read_csv('products_.csv')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining methods"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie chart\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "def pie_chart(labels, sizes):\n",
    "    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
    "            shadow=True, startangle=90)\n",
    "    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the customer data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_data(customer_id):\n",
    "    transactions = transactions_raw[transactions_raw['CUSTOMER'] == customer_id]\n",
    "    products = products_raw[products_raw['SKU'].isin(transactions['SKU'])]\n",
    "    products['COLOR'] = products['ATTRIBUTES'].apply(lambda x: json.loads(x)['color'])\n",
    "    products['BRAND'] = products['ATTRIBUTES'].apply(lambda x: json.loads(x)['brand'].upper())\n",
    "    return products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Customer data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_customer_data(products):\n",
    "    grouped_brands = products['BRAND'].value_counts().rename_axis('BRAND').reset_index(name='COUNT')\n",
    "    grouped_colors = products['COLOR'].value_counts().rename_axis('COLOR').reset_index(name='COUNT')\n",
    "    grouped_categories = products['NAME'].value_counts().rename_axis('CATEGORY').reset_index(name='COUNT')\n",
    "    pie_chart(grouped_brands['BRAND'], grouped_brands['COUNT'])\n",
    "    pie_chart(grouped_colors['COLOR'], grouped_colors['COUNT'])\n",
    "    pie_chart(grouped_categories['CATEGORY'], grouped_categories['COUNT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data for model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_item_purchase_count(transactions):\n",
    "    transactions_count = transactions.groupby(['SKU', 'CUSTOMER']).size().reset_index(name='COUNT')\n",
    "    transactions_count = transactions_count.join(transactions_count.groupby(['SKU'])['COUNT'].transform(lambda x: x / x.sum()), rsuffix='_FREQ')\n",
    "    return transactions_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(transactions):\n",
    "    train, test = train_test_split(transactions, test_size = .2)\n",
    "    train = tc.SFrame(train)\n",
    "    test = tc.SFrame(test)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normilized_data():\n",
    "    transactions = normalize_item_purchase_count(transactions_raw)\n",
    "    train, test = get_train_test_data(transactions)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_data, name, user_id, item_id, target, users_to_recommend, n_rec, n_display):\n",
    "    if name == 'popularity':\n",
    "        model = tc.popularity_recommender.create(train_data, \n",
    "                                                    user_id=user_id, \n",
    "                                                    item_id=item_id, \n",
    "                                                    target=target)\n",
    "    elif name == 'cosine':\n",
    "        model = tc.item_similarity_recommender.create(train_data, \n",
    "                                                    user_id=user_id, \n",
    "                                                    item_id=item_id, \n",
    "                                                    target=target, \n",
    "                                                    similarity_type='cosine')\n",
    "    elif name == 'pearson':\n",
    "        model = tc.item_similarity_recommender.create(train_data, \n",
    "                                                    user_id=user_id, \n",
    "                                                    item_id=item_id, \n",
    "                                                    target=target, \n",
    "                                                    similarity_type='pearson')\n",
    "        \n",
    "    recom = model.recommend(users=users_to_recommend, k=n_rec)\n",
    "    recom.print_rows(n_display)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a recommendation "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(similarity, train):\n",
    "    user_id = 'CUSTOMER'\n",
    "    item_id = 'SKU'\n",
    "    users_to_recommend = list([])\n",
    "    n_rec = 10 # number of items to recommend\n",
    "    n_display = 30 # to display the first few rows in an output dataset\n",
    "    target = 'COUNT'\n",
    "    \n",
    "    popularity = model(train, similarity, user_id, item_id, target, users_to_recommend, n_rec, n_display)\n",
    "    return popularity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_product_info(items):\n",
    "    products_rec = products_raw[products_raw['SKU'].isin(items['SKU'])] \n",
    "    products_rec['COLOR'] = products_rec['ATTRIBUTES'].apply(lambda x: json.loads(x)['color'])\n",
    "    products_rec['BRAND'] = products_rec['ATTRIBUTES'].apply(lambda x: json.loads(x)['brand'].upper())\n",
    "    products_rec = ps.merge(items, products_rec, how='left', on=['SKU']).drop_duplicates(subset=['SKU'])\n",
    "    return products_rec[['rank','score','NAME','BRAND', 'COLOR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation_for_user(customer_id, trained_model):\n",
    "    recommended_items = trained_model[trained_model['CUSTOMER']==customer_id].to_dataframe()\n",
    "    print(merge_product_info(recommended_items))\n",
    "    visualize_customer_data(get_customer_data(customer_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(models_w_norm, test_data):\n",
    "    names_w_norm = ['Popularity Model on Scaled Purchase Counts', 'Cosine Similarity on Scaled Purchase Counts', 'Pearson Similarity on Scaled Purchase Counts']\n",
    "    eval_norm = tc.recommender.util.compare_models(test_data, models_w_norm, model_names=names_w_norm)\n",
    "    return eval_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_id = 1006890\n",
    "# train_norm, test_norm = get_normilized_data()\n",
    "# trained_model = get_model('cosine', train_norm)\n",
    "# recommentations_data = trained_model.recommend()\n",
    "# get_recommendation_for_user(customer_id, recommentations_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and evalute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm, test_norm = get_normilized_data()\n",
    "pop_norm = get_model('popularity', train_norm)\n",
    "cos_norm = get_model('cosine', train_norm)\n",
    "pear_norm = get_model('pearson', train_norm)\n",
    "\n",
    "models_w_norm = [pop_norm, cos_norm, pear_norm]\n",
    "evaluate(models_w_norm, test_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Unable to load model from /home/behnam/projects/ml-guild-notes/pop_norm: Archive does not contain a model.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2903b7c66b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpop_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pop_norm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcos_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cos_norm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpear_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pear_norm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodels_w_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpop_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpear_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_w_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/local/lib/python3.6/site-packages/turicreate/toolkits/_model.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0m_internal_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_internal_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0msaved_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglconnect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_internal_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0msaved_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrap_function_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m# The archive version could be both bytes/unicode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcy_unity.pyx\u001b[0m in \u001b[0;36mturicreate._cython.cy_unity.UnityGlobalProxy.load_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcy_unity.pyx\u001b[0m in \u001b[0;36mturicreate._cython.cy_unity.UnityGlobalProxy.load_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to load model from /home/behnam/projects/ml-guild-notes/pop_norm: Archive does not contain a model."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}